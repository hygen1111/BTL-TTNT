# -*- coding: utf-8 -*-
"""crnnctcp1.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1xeBfSBDtESNd3QoK1iQYBpXYgxi-wAwl
"""

from google.colab import drive
drive.mount('/content/gdrive')
import os
import cv2
import numpy as np
import torch
import pandas as pd
import random
import torch.nn as nn
from torch.utils.data import Dataset, DataLoader
import matplotlib.pyplot as plt

!pip install torch torchvision torchaudio opencv-python pandas tqdm

CHARS = "0123456789ABCDEFGHKLMNPRSTUVXYZ"
TRAIN_IMG_DIR = "/content/gdrive/MyDrive/BTL-TTNT/5_CRNN_DATASET/train"
TRAIN_LABEL_CSV = "/content/gdrive/MyDrive/BTL-TTNT/train_labels.csv"
TEST_IMG_DIR = "/content/gdrive/MyDrive/BTL-TTNT/5_CRNN_DATASET/test"
TEST_LABEL_CSV = "/content/gdrive/MyDrive/BTL-TTNT/test_labels.csv"
def preprocess(img):
    h, w = img.shape[:2]
    new_h = 32
    new_w = int(w * new_h / h)
    new_w = max(new_w, 160)
    img = cv2.resize(img, (new_w, new_h))
    img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
    img = cv2.equalizeHist(img)
    img = cv2.GaussianBlur(img, (3,3), 0)
    canny = cv2.Canny(img, 50, 150)
    # Giảm trọng số canny xuống 0.1 để tránh nhiễu giả
    img = cv2.addWeighted(img, 1.8, canny, 0.1, 0)
    img = img / 255.0
    return img

class PlateDataset(Dataset):
    def __init__(self, img_dir, csv_file, augment=True):
        self.img_dir = img_dir
        self.df = pd.read_csv(csv_file)
        self.augment = augment

    def __len__(self):
        return len(self.df)

    def __getitem__(self, idx):
        row = self.df.iloc[idx]
        img_path = os.path.join(self.img_dir, str(row['image']))
        img = cv2.imread(img_path)

        if img is None:
            img = np.zeros((32, 100, 3), dtype=np.uint8)
            label = "0"
        else:
            label = str(row['label']).upper()

        if self.augment:
            # Xoay mạnh hơn
            angle = random.uniform(-8, 8)
            h, w = img.shape[:2]
            M = cv2.getRotationMatrix2D((w//2, h//2), angle, 1.0)
            img = cv2.warpAffine(img, M, (w, h))
            # Độ tương phản & Độ sáng
            alpha = random.uniform(0.7, 1.3)
            beta = random.randint(-40, 40)
            img = cv2.convertScaleAbs(img, alpha=alpha, beta=beta)
            # Nhiễu/Mờ
            if random.random() > 0.5:
                img = cv2.GaussianBlur(img, (3,3), 0)

        img = preprocess(img)
        img = torch.tensor(img).unsqueeze(0).float()
        label_idx = [CHARS.index(c) + 1 for c in label if c in CHARS]
        return img, torch.tensor(label_idx, dtype=torch.long), len(label_idx)

def collate_fn(batch):
    imgs, labels, lengths = zip(*batch)
    max_w = max(img.shape[-1] for img in imgs)
    padded_imgs = []
    for img in imgs:
        c, h, w = img.shape
        pad = torch.zeros((c, h, max_w - w))
        img = torch.cat([img, pad], dim=2)
        padded_imgs.append(img)
    return torch.stack(padded_imgs), torch.cat(labels), torch.tensor(lengths)

class CRNN(nn.Module):
    def __init__(self, imgH, nc, nclass, nh):
        super(CRNN, self).__init__()
        self.cnn = nn.Sequential(
            nn.Conv2d(nc, 64, 3, 1, 1), nn.ReLU(True), nn.MaxPool2d(2, 2),
            nn.Conv2d(64, 128, 3, 1, 1), nn.ReLU(True), nn.MaxPool2d(2, 2),
            nn.Conv2d(128, 256, 3, 1, 1), nn.BatchNorm2d(256), nn.ReLU(True),
            nn.Conv2d(256, 256, 3, 1, 1), nn.ReLU(True), nn.MaxPool2d((2,1), (2,1)),
            nn.Conv2d(256, 512, 3, 1, 1), nn.BatchNorm2d(512), nn.ReLU(True),
            nn.Conv2d(512, 512, 3, 1, 1), nn.ReLU(True), nn.MaxPool2d((2,1), (2,1)),
            nn.Conv2d(512, 512, 2, 1, 0), nn.ReLU(True)
        )
        self.rnn = nn.LSTM(512, nh, num_layers=2, bidirectional=True, batch_first=True, dropout=0.3)
        self.fc = nn.Sequential(
            nn.Dropout(0.3),
            nn.Linear(nh * 2, nclass)
        )

    def forward(self, x):
        x = self.cnn(x)
        x = x.squeeze(2).permute(0, 2, 1)
        x, _ = self.rnn(x)
        return self.fc(x)

def decode_predictions(preds, chars):
    preds = preds.argmax(2).transpose(1, 0).contiguous().cpu().numpy()
    decoded_texts = []
    for p in preds:
        tokens = []
        for i in range(len(p)):
            if p[i] != 0 and (not (i > 0 and p[i] == p[i-1])):
                tokens.append(chars[p[i] - 1])
        decoded_texts.append("".join(tokens))
    return decoded_texts

def train_one_epoch(model, loader, optimizer, criterion):
    model.train()
    total_loss = 0
    for imgs, labels, lengths in loader:
        imgs, labels, lengths = imgs.cuda(), labels.cuda(), lengths.cuda()
        preds = model(imgs).log_softmax(2).permute(1, 0, 2)
        input_lengths = torch.full((imgs.size(0),), preds.size(0), dtype=torch.long).cuda()
        loss = criterion(preds, labels, input_lengths, lengths)
        optimizer.zero_grad()
        loss.backward()
        optimizer.step()
        total_loss += loss.item()
    return total_loss / len(loader)

def evaluate(model, loader):
    model.eval()
    correct, total = 0, 0
    with torch.no_grad():
        for imgs, labels, lengths in loader:
            imgs = imgs.cuda()
            preds = model(imgs).log_softmax(2).permute(1, 0, 2)
            pred_texts = decode_predictions(preds, CHARS)
            targets, curr = [], 0
            for l in lengths:
                targets.append("".join([CHARS[i-1] for i in labels[curr:curr+l]]))
                curr += l
            for p, t in zip(pred_texts, targets):
                if p == t: correct += 1
                total += 1
    return (correct / total) * 100 if total > 0 else 0

# Setup
train_loader = DataLoader(PlateDataset(TRAIN_IMG_DIR, TRAIN_LABEL_CSV, augment=True), batch_size=32, shuffle=True, collate_fn=collate_fn)
test_loader = DataLoader(PlateDataset(TEST_IMG_DIR, TEST_LABEL_CSV, augment=False), batch_size=32, collate_fn=collate_fn)

model = CRNN(imgH=32, nc=1, nclass=len(CHARS) + 1, nh=256).cuda()
criterion = nn.CTCLoss(blank=0, zero_infinity=True)
optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)
scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=5)

best_test_acc = 0.0
num_epochs = 100

for epoch in range(num_epochs):
    loss = train_one_epoch(model, train_loader, optimizer, criterion)
    scheduler.step(loss)

    # Đánh giá trên tập TEST sau mỗi epoch
    test_acc = evaluate(model, test_loader)

    print(f"Epoch [{epoch+1}/{num_epochs}] - Loss: {loss:.4f} - Test Acc: {test_acc:.2f}% - LR: {optimizer.param_groups[0]['lr']}")

    # LƯU MODEL TỐT NHẤT
    if test_acc > best_test_acc:
        best_test_acc = test_acc
        save_path = '/content/gdrive/MyDrive/BTL-TTNT/crnn_best_model.pth'
        torch.save(model.state_dict(), save_path)
        print(f" Đã lưu Model mới tốt nhất với Acc: {best_test_acc:.2f}%")

print(f"\nHoàn thành! Độ chính xác cao nhất đạt được trên tập Test: {best_test_acc:.2f}%")

extra_epochs = 100
patience = 20
no_improve_count = 0

print(f"Bắt đầu huấn luyện giai đoạn 2 (tối đa {extra_epochs} epoch)...")

for epoch in range(extra_epochs):
    # 1. Huấn luyện
    loss = train_one_epoch(model, train_loader, optimizer, criterion)
    scheduler.step(loss)

    # 2. Đánh giá
    test_acc = evaluate(model, test_loader)
    current_lr = optimizer.param_groups[0]['lr']

    print(f"Epoch [{epoch + 101}/{100 + extra_epochs}] - Loss: {loss:.4f} - Test Acc: {test_acc:.2f}% - LR: {current_lr}")

    # 3. Kiểm tra cải thiện và Lưu model
    if test_acc > best_test_acc:
        best_test_acc = test_acc
        no_improve_count = 0 # Reset bộ đếm nếu có cải thiện
        save_path = '/content/gdrive/MyDrive/BTL-TTNT/crnn_best_model.pth'
        torch.save(model.state_dict(), save_path)
        print(f" KỶ LỤC MỚI: {best_test_acc:.2f}% - Đã lưu model.")
    else:
        no_improve_count += 1

    # 4. Cơ chế Early Stopping
    if no_improve_count >= patience:
        print(f"\n[DỪNG SỚM] Kết quả không cải thiện sau {patience} epoch liên tiếp.")
        print(f"Mô hình đã đạt trạng thái tốt nhất tại Acc: {best_test_acc:.2f}%")
        break

print("\n Quá trình huấn luyện đã kết thúc.")

import matplotlib.pyplot as plt

def visualize_errors(model, loader, num_samples=10):
    model.eval()
    errors = []

    print("Đang tìm kiếm các mẫu dự đoán sai...")
    with torch.no_grad():
        for imgs, labels, lengths in loader:
            imgs_cuda = imgs.cuda()
            preds = model(imgs_cuda).log_softmax(2).permute(1, 0, 2)
            pred_texts = decode_predictions(preds, CHARS)

            # Giải mã nhãn gốc
            targets = []
            curr = 0
            for l in lengths:
                t_text = "".join([CHARS[i-1] for i in labels[curr:curr+l]])
                targets.append(t_text)
                curr += l

            # Lưu các mẫu sai
            for i in range(len(pred_texts)):
                if pred_texts[i] != targets[i]:
                    # Chuyển tensor ảnh về định dạng numpy để hiển thị
                    img_np = imgs[i].squeeze().cpu().numpy()
                    errors.append((img_np, targets[i], pred_texts[i]))

                if len(errors) >= num_samples:
                    break
            if len(errors) >= num_samples:
                break
    # Hiển thị
    if not errors:
        print("Chúc mừng! Không tìm thấy mẫu sai nào trong tập Test.")
        return

    cols = 2
    rows = (len(errors) + 1) // 2
    plt.figure(figsize=(12, rows * 3))

    for i, (img, target, pred) in enumerate(errors):
        plt.subplot(rows, cols, i + 1)
        plt.imshow(img, cmap='gray')
        plt.title(f"Gốc: {target} | Đoán: {pred}", color='red')
        plt.axis('off')

    plt.tight_layout()
    plt.show()
visualize_errors(model, test_loader)